# -*- coding: utf-8 -*-
"""Booster_Algo_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZjiPAsTFFZfRJKZ5MPgjxfxRoGYiNmHr
"""

!pip install langdetect

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
import random
from os.path import join, dirname

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')
import string
import nltk
from nltk import PorterStemmer
import re
nltk.download('stopwords')
nltk.download('wordnet')
stopwords = nltk.corpus.stopwords.words('english')
import nltk
nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords

from gensim import corpora
import gensim
from gensim.test.utils import common_texts, get_tmpfile
from gensim.models import Word2Vec
from gensim.sklearn_api import W2VTransformer
from sklearn.metrics import confusion_matrix, f1_score, classification_report
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

#Collecting input from the URL given
URL_training  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'
URL_validation  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/valid.tsv'
URL_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'

df_training = pd.read_table(URL_training,
                             names = ['id',	'label'	,'statement',	'subject',	'speaker', 	'job', 	'state',	'party',	'barely_true_c',	'false_c',	'half_true_c',	'mostly_true_c',	'pants_on_fire_c',	'venue'])

    
df_validation = pd.read_table(URL_validation,
                             names =['id',	'label'	,'statement',	'subject',	'speaker', 	'job', 	'state',	'party',	'barely_true_c',	'false_c',	'half_true_c',	'mostly_true_c',	'pants_on_fire_c',	'venue'])


df_test = pd.read_csv(URL_test, sep='\t', 
                            names =['id',	'label'	,'statement',	'subject',	'speaker', 	'job', 	'state',	'party',	'barely_true_c',	'false_c',	'half_true_c',	'mostly_true_c',	'pants_on_fire_c',	'venue'])

df_training.loc[0,:]

df_training

df_training_statement = df_training.loc[:,"statement"]
df_training_statement

df_training_label = df_training.loc[:,"label"]
df_training_label

df_validation_statement = df_validation.loc[:,"statement"]
df_validation_statement

df_validation_label = df_validation.loc[:,"label"]
df_validation_label

df_test_statement = df_test.loc[:,"statement"]
df_test_statement

df_test_label = df_test.loc[:,"label"]
df_test_label

# Training the model  
from sklearn.ensemble import BaggingClassifier as BRC
from sklearn.ensemble import ExtraTreesClassifier as ETC
pipeline = Pipeline([
        ('ngrams', TfidfVectorizer(ngram_range=(1, 1))),
        ('clf', BRC(base_estimator=ETC(n_estimators=30), n_estimators=100,bootstrap_features=True,oob_score=True,max_features = 7))
    ])
pipeline.fit(df_training_statement, df_training_label)

predicted_labels = pipeline.predict(df_validation_statement)
predicted_labels

accuracy = pipeline.score(df_validation_label,predicted_labels)
accuracy

predicted_labels_test = pipeline.predict(df_test_statement)
predicted_labels_test

accuracy_test = pipeline.score(df_test_label,predicted_labels_test)
accuracy_test

# now solving the first task i.e classifying into two categories : true and false

# Converting six types of label to 2 types of label in Training Data

Binary_label = []
for row in df_training["label"]:
        if row == "true":
            Binary_label.append("true")
        elif row == "half-true":
            Binary_label.append("true")
        elif row == "barely-true":
            Binary_label.append("true")
        elif row == "mostly-true":
            Binary_label.append("true")
        elif row == "false":
            Binary_label.append("false")
        elif row == "mostly-false":
            Binary_label.append("false")    
        elif row == "pants-fire":
            Binary_label.append("false")
        else: Binary_label.append("NAN")
 
       
df_training["new_label"] = Binary_label

# Converting six types of label to 2 types of label in Validation Data

Binary_label_validation = []
for row in df_validation["label"]:
        if row == "true":
            Binary_label_validation.append("true")
        elif row == "half-true":
            Binary_label_validation.append("true")
        elif row == "barely-true":
            Binary_label_validation.append("true")
        elif row == "mostly-true":
            Binary_label_validation.append("true")
        elif row == "false":
            Binary_label_validation.append("false")
        elif row == "mostly-false":
            Binary_label_validation.append("false")    
        elif row == "pants-fire":
            Binary_label_validation.append("false")
        else: Binary_label_validation.append("NAN")
 
       
df_validation["new_label"] = Binary_label_validation

# Converting six types of label to 2 types of label in Test Data

Binary_label_test = []
for row in df_test["label"]:
        if row == "true":
            Binary_label_test.append("true")
        elif row == "half-true":
            Binary_label_test.append("true")
        elif row == "barely-true":
            Binary_label_test.append("true")
        elif row == "mostly-true":
            Binary_label_test.append("true")
        elif row == "false":
            Binary_label_test.append("false")
        elif row == "mostly-false":
            Binary_label_test.append("false")    
        elif row == "pants-fire":
            Binary_label_test.append("false")
        else: Binary_label_test.append("NAN")
 
       
df_test["new_label"] = Binary_label_test

df_training_new_label = df_training.loc[:,"new_label"]
df_validation_new_label = df_validation.loc[:,"new_label"]
df_test_new_label = df_test.loc[:,"new_label"]

pipeline_1 = Pipeline([
        ('ngrams', TfidfVectorizer(ngram_range=(1, 1))),
        ('clf', BRC(base_estimator=ETC(n_estimators=30), n_estimators=100,bootstrap_features=True,oob_score=True,max_features = 7))
    ])
pipeline_1.fit(df_training_statement, df_training_new_label)

predicted_labels_1 = pipeline_1.predict(df_validation_statement)
predicted_labels_1

accuracy_1 = pipeline_1.score(df_validation_new_label,predicted_labels_1)
accuracy_1

predicted_labels_1_test = pipeline_1.predict(df_test_statement)
predicted_labels_1_test

accuracy_1_test = pipeline_1.score(df_test_new_label,predicted_labels_1_test)
accuracy_1_test

